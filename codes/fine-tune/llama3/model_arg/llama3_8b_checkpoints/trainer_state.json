{
  "best_metric": 0.0304227527230978,
  "best_model_checkpoint": "/root/nas/202409_SMCR/ARR_SMCR/finetuning/llama3/model_arg/20241213_1/checkpoint-1000",
  "epoch": 1.3463480309660047,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013463480309660047,
      "grad_norm": 7.377011299133301,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.9145,
      "step": 10
    },
    {
      "epoch": 0.026926960619320095,
      "grad_norm": 8.713228225708008,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.7706,
      "step": 20
    },
    {
      "epoch": 0.04039044092898014,
      "grad_norm": 3.3903093338012695,
      "learning_rate": 5.8e-06,
      "loss": 0.4317,
      "step": 30
    },
    {
      "epoch": 0.05385392123864019,
      "grad_norm": 3.2829184532165527,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.2742,
      "step": 40
    },
    {
      "epoch": 0.06731740154830024,
      "grad_norm": 2.774157762527466,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.1535,
      "step": 50
    },
    {
      "epoch": 0.08078088185796028,
      "grad_norm": 1.3999584913253784,
      "learning_rate": 1.16e-05,
      "loss": 0.1076,
      "step": 60
    },
    {
      "epoch": 0.09424436216762033,
      "grad_norm": 1.898964524269104,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0762,
      "step": 70
    },
    {
      "epoch": 0.10770784247728038,
      "grad_norm": 1.0008430480957031,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0789,
      "step": 80
    },
    {
      "epoch": 0.12117132278694043,
      "grad_norm": 0.674716055393219,
      "learning_rate": 1.76e-05,
      "loss": 0.0525,
      "step": 90
    },
    {
      "epoch": 0.13463480309660047,
      "grad_norm": 1.7952934503555298,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0556,
      "step": 100
    },
    {
      "epoch": 0.14809828340626052,
      "grad_norm": 0.5437905788421631,
      "learning_rate": 1.9998351208997734e-05,
      "loss": 0.0481,
      "step": 110
    },
    {
      "epoch": 0.16156176371592057,
      "grad_norm": 0.8272510766983032,
      "learning_rate": 1.9991653927373767e-05,
      "loss": 0.0651,
      "step": 120
    },
    {
      "epoch": 0.17502524402558062,
      "grad_norm": 0.4503098130226135,
      "learning_rate": 1.997980855373773e-05,
      "loss": 0.0424,
      "step": 130
    },
    {
      "epoch": 0.18848872433524066,
      "grad_norm": 0.4928295910358429,
      "learning_rate": 1.9962821191290738e-05,
      "loss": 0.0436,
      "step": 140
    },
    {
      "epoch": 0.2019522046449007,
      "grad_norm": 1.019768476486206,
      "learning_rate": 1.9940700592588228e-05,
      "loss": 0.0463,
      "step": 150
    },
    {
      "epoch": 0.21541568495456076,
      "grad_norm": 0.7116630673408508,
      "learning_rate": 1.9913458155030303e-05,
      "loss": 0.0316,
      "step": 160
    },
    {
      "epoch": 0.2288791652642208,
      "grad_norm": 0.5217252373695374,
      "learning_rate": 1.9881107914989338e-05,
      "loss": 0.0424,
      "step": 170
    },
    {
      "epoch": 0.24234264557388085,
      "grad_norm": 0.600618302822113,
      "learning_rate": 1.98436665405779e-05,
      "loss": 0.0382,
      "step": 180
    },
    {
      "epoch": 0.2558061258835409,
      "grad_norm": 0.4717828929424286,
      "learning_rate": 1.9801153323060667e-05,
      "loss": 0.0338,
      "step": 190
    },
    {
      "epoch": 0.26926960619320095,
      "grad_norm": 0.2914581894874573,
      "learning_rate": 1.9753590166914828e-05,
      "loss": 0.0519,
      "step": 200
    },
    {
      "epoch": 0.282733086502861,
      "grad_norm": 0.6010127067565918,
      "learning_rate": 1.970100157854402e-05,
      "loss": 0.0498,
      "step": 210
    },
    {
      "epoch": 0.29619656681252104,
      "grad_norm": 0.8407551050186157,
      "learning_rate": 1.9643414653651697e-05,
      "loss": 0.0537,
      "step": 220
    },
    {
      "epoch": 0.3096600471221811,
      "grad_norm": 0.4543328285217285,
      "learning_rate": 1.9580859063280326e-05,
      "loss": 0.0423,
      "step": 230
    },
    {
      "epoch": 0.32312352743184114,
      "grad_norm": 1.2052403688430786,
      "learning_rate": 1.951336703852372e-05,
      "loss": 0.037,
      "step": 240
    },
    {
      "epoch": 0.3365870077415012,
      "grad_norm": 0.9063194394111633,
      "learning_rate": 1.9440973353920315e-05,
      "loss": 0.0348,
      "step": 250
    },
    {
      "epoch": 0.35005048805116123,
      "grad_norm": 0.5970600247383118,
      "learning_rate": 1.9363715309535956e-05,
      "loss": 0.0479,
      "step": 260
    },
    {
      "epoch": 0.3635139683608213,
      "grad_norm": 0.960811972618103,
      "learning_rate": 1.928163271174546e-05,
      "loss": 0.0343,
      "step": 270
    },
    {
      "epoch": 0.37697744867048133,
      "grad_norm": 0.9287095069885254,
      "learning_rate": 1.9194767852722777e-05,
      "loss": 0.0318,
      "step": 280
    },
    {
      "epoch": 0.3904409289801414,
      "grad_norm": 1.1696538925170898,
      "learning_rate": 1.9103165488650425e-05,
      "loss": 0.04,
      "step": 290
    },
    {
      "epoch": 0.4039044092898014,
      "grad_norm": 1.195027232170105,
      "learning_rate": 1.9006872816659355e-05,
      "loss": 0.0337,
      "step": 300
    },
    {
      "epoch": 0.4173678895994615,
      "grad_norm": 0.6641995906829834,
      "learning_rate": 1.8905939450511117e-05,
      "loss": 0.0449,
      "step": 310
    },
    {
      "epoch": 0.4308313699091215,
      "grad_norm": 0.7660091519355774,
      "learning_rate": 1.8800417395034927e-05,
      "loss": 0.0294,
      "step": 320
    },
    {
      "epoch": 0.44429485021878157,
      "grad_norm": 0.9193059802055359,
      "learning_rate": 1.869036101933272e-05,
      "loss": 0.0327,
      "step": 330
    },
    {
      "epoch": 0.4577583305284416,
      "grad_norm": 1.1338104009628296,
      "learning_rate": 1.8575827028766062e-05,
      "loss": 0.0392,
      "step": 340
    },
    {
      "epoch": 0.47122181083810166,
      "grad_norm": 1.1478705406188965,
      "learning_rate": 1.8456874435739337e-05,
      "loss": 0.0315,
      "step": 350
    },
    {
      "epoch": 0.4846852911477617,
      "grad_norm": 0.8598058819770813,
      "learning_rate": 1.833356452929421e-05,
      "loss": 0.035,
      "step": 360
    },
    {
      "epoch": 0.49814877145742176,
      "grad_norm": 0.9336531162261963,
      "learning_rate": 1.820596084353115e-05,
      "loss": 0.0343,
      "step": 370
    },
    {
      "epoch": 0.5116122517670818,
      "grad_norm": 0.494201123714447,
      "learning_rate": 1.8074129124874137e-05,
      "loss": 0.0332,
      "step": 380
    },
    {
      "epoch": 0.5250757320767419,
      "grad_norm": 1.0612629652023315,
      "learning_rate": 1.793813729819553e-05,
      "loss": 0.0374,
      "step": 390
    },
    {
      "epoch": 0.5385392123864019,
      "grad_norm": 1.806712031364441,
      "learning_rate": 1.779805543181854e-05,
      "loss": 0.0272,
      "step": 400
    },
    {
      "epoch": 0.552002692696062,
      "grad_norm": 0.8888654708862305,
      "learning_rate": 1.7653955701415225e-05,
      "loss": 0.0376,
      "step": 410
    },
    {
      "epoch": 0.565466173005722,
      "grad_norm": 0.47092679142951965,
      "learning_rate": 1.750591235281881e-05,
      "loss": 0.0438,
      "step": 420
    },
    {
      "epoch": 0.578929653315382,
      "grad_norm": 0.576461911201477,
      "learning_rate": 1.7354001663769278e-05,
      "loss": 0.0337,
      "step": 430
    },
    {
      "epoch": 0.5923931336250421,
      "grad_norm": 1.6257978677749634,
      "learning_rate": 1.7198301904612116e-05,
      "loss": 0.04,
      "step": 440
    },
    {
      "epoch": 0.6058566139347021,
      "grad_norm": 0.9415444135665894,
      "learning_rate": 1.7038893297970346e-05,
      "loss": 0.0329,
      "step": 450
    },
    {
      "epoch": 0.6193200942443622,
      "grad_norm": 0.46160876750946045,
      "learning_rate": 1.6875857977410692e-05,
      "loss": 0.028,
      "step": 460
    },
    {
      "epoch": 0.6327835745540222,
      "grad_norm": 0.7242702841758728,
      "learning_rate": 1.670927994512514e-05,
      "loss": 0.0242,
      "step": 470
    },
    {
      "epoch": 0.6462470548636823,
      "grad_norm": 2.188648223876953,
      "learning_rate": 1.6539245028649713e-05,
      "loss": 0.0385,
      "step": 480
    },
    {
      "epoch": 0.6597105351733423,
      "grad_norm": 1.168422818183899,
      "learning_rate": 1.636584083664276e-05,
      "loss": 0.049,
      "step": 490
    },
    {
      "epoch": 0.6731740154830024,
      "grad_norm": 0.471506804227829,
      "learning_rate": 1.618915671374554e-05,
      "loss": 0.0358,
      "step": 500
    },
    {
      "epoch": 0.6731740154830024,
      "eval_loss": 0.0355307012796402,
      "eval_runtime": 309.4298,
      "eval_samples_per_second": 4.269,
      "eval_steps_per_second": 4.269,
      "step": 500
    },
    {
      "epoch": 0.6866374957926624,
      "grad_norm": 0.30361732840538025,
      "learning_rate": 1.6009283694548365e-05,
      "loss": 0.0316,
      "step": 510
    },
    {
      "epoch": 0.7001009761023225,
      "grad_norm": 0.7266066074371338,
      "learning_rate": 1.582631445668599e-05,
      "loss": 0.0425,
      "step": 520
    },
    {
      "epoch": 0.7135644564119825,
      "grad_norm": 0.6744447946548462,
      "learning_rate": 1.5640343273086466e-05,
      "loss": 0.0373,
      "step": 530
    },
    {
      "epoch": 0.7270279367216426,
      "grad_norm": 0.36531686782836914,
      "learning_rate": 1.5451465963398056e-05,
      "loss": 0.0401,
      "step": 540
    },
    {
      "epoch": 0.7404914170313026,
      "grad_norm": 0.328437477350235,
      "learning_rate": 1.5259779844619152e-05,
      "loss": 0.0281,
      "step": 550
    },
    {
      "epoch": 0.7539548973409627,
      "grad_norm": 0.738535463809967,
      "learning_rate": 1.5065383680956776e-05,
      "loss": 0.0284,
      "step": 560
    },
    {
      "epoch": 0.7674183776506227,
      "grad_norm": 1.3678395748138428,
      "learning_rate": 1.4868377632939361e-05,
      "loss": 0.0357,
      "step": 570
    },
    {
      "epoch": 0.7808818579602828,
      "grad_norm": 0.9136846661567688,
      "learning_rate": 1.4668863205810136e-05,
      "loss": 0.0328,
      "step": 580
    },
    {
      "epoch": 0.7943453382699428,
      "grad_norm": 0.636526346206665,
      "learning_rate": 1.446694319722763e-05,
      "loss": 0.0319,
      "step": 590
    },
    {
      "epoch": 0.8078088185796028,
      "grad_norm": 0.6907745599746704,
      "learning_rate": 1.4262721644300294e-05,
      "loss": 0.0368,
      "step": 600
    },
    {
      "epoch": 0.8212722988892629,
      "grad_norm": 0.6202813982963562,
      "learning_rate": 1.4056303769982508e-05,
      "loss": 0.0363,
      "step": 610
    },
    {
      "epoch": 0.834735779198923,
      "grad_norm": 0.7531071901321411,
      "learning_rate": 1.3847795928859568e-05,
      "loss": 0.0212,
      "step": 620
    },
    {
      "epoch": 0.848199259508583,
      "grad_norm": 0.4059115946292877,
      "learning_rate": 1.3637305552349656e-05,
      "loss": 0.0301,
      "step": 630
    },
    {
      "epoch": 0.861662739818243,
      "grad_norm": 1.4840800762176514,
      "learning_rate": 1.3424941093350933e-05,
      "loss": 0.0383,
      "step": 640
    },
    {
      "epoch": 0.8751262201279031,
      "grad_norm": 0.7394737601280212,
      "learning_rate": 1.321081197036238e-05,
      "loss": 0.0207,
      "step": 650
    },
    {
      "epoch": 0.8885897004375631,
      "grad_norm": 0.07530739158391953,
      "learning_rate": 1.2995028511107077e-05,
      "loss": 0.0209,
      "step": 660
    },
    {
      "epoch": 0.9020531807472232,
      "grad_norm": 0.6503088474273682,
      "learning_rate": 1.2777701895687034e-05,
      "loss": 0.0225,
      "step": 670
    },
    {
      "epoch": 0.9155166610568832,
      "grad_norm": 1.2365577220916748,
      "learning_rate": 1.2558944099298853e-05,
      "loss": 0.0316,
      "step": 680
    },
    {
      "epoch": 0.9289801413665433,
      "grad_norm": 1.9656697511672974,
      "learning_rate": 1.23388678345397e-05,
      "loss": 0.0341,
      "step": 690
    },
    {
      "epoch": 0.9424436216762033,
      "grad_norm": 0.43006113171577454,
      "learning_rate": 1.2117586493333365e-05,
      "loss": 0.0338,
      "step": 700
    },
    {
      "epoch": 0.9559071019858634,
      "grad_norm": 0.8156231045722961,
      "learning_rate": 1.1895214088506284e-05,
      "loss": 0.0302,
      "step": 710
    },
    {
      "epoch": 0.9693705822955234,
      "grad_norm": 1.0895346403121948,
      "learning_rate": 1.1671865195043678e-05,
      "loss": 0.0188,
      "step": 720
    },
    {
      "epoch": 0.9828340626051835,
      "grad_norm": 0.817766010761261,
      "learning_rate": 1.1447654891056005e-05,
      "loss": 0.0291,
      "step": 730
    },
    {
      "epoch": 0.9962975429148435,
      "grad_norm": 0.749974250793457,
      "learning_rate": 1.1222698698486221e-05,
      "loss": 0.0273,
      "step": 740
    },
    {
      "epoch": 1.0097610232245036,
      "grad_norm": 0.3151713013648987,
      "learning_rate": 1.0997112523588322e-05,
      "loss": 0.016,
      "step": 750
    },
    {
      "epoch": 1.0232245035341636,
      "grad_norm": 0.1935720294713974,
      "learning_rate": 1.0771012597207923e-05,
      "loss": 0.0188,
      "step": 760
    },
    {
      "epoch": 1.0366879838438237,
      "grad_norm": 0.5948229432106018,
      "learning_rate": 1.0544515414895552e-05,
      "loss": 0.0169,
      "step": 770
    },
    {
      "epoch": 1.0501514641534837,
      "grad_norm": 0.5328295826911926,
      "learning_rate": 1.0317737676883563e-05,
      "loss": 0.0238,
      "step": 780
    },
    {
      "epoch": 1.0636149444631438,
      "grad_norm": 0.7216308116912842,
      "learning_rate": 1.0090796227957633e-05,
      "loss": 0.0389,
      "step": 790
    },
    {
      "epoch": 1.0770784247728038,
      "grad_norm": 0.28551918268203735,
      "learning_rate": 9.863807997253701e-06,
      "loss": 0.0192,
      "step": 800
    },
    {
      "epoch": 1.0905419050824638,
      "grad_norm": 0.27522072196006775,
      "learning_rate": 9.636889938011524e-06,
      "loss": 0.0244,
      "step": 810
    },
    {
      "epoch": 1.104005385392124,
      "grad_norm": 1.1307954788208008,
      "learning_rate": 9.41015896731577e-06,
      "loss": 0.0289,
      "step": 820
    },
    {
      "epoch": 1.117468865701784,
      "grad_norm": 0.6266137361526489,
      "learning_rate": 9.183731905855746e-06,
      "loss": 0.018,
      "step": 830
    },
    {
      "epoch": 1.130932346011444,
      "grad_norm": 0.8511270880699158,
      "learning_rate": 8.957725417734802e-06,
      "loss": 0.0272,
      "step": 840
    },
    {
      "epoch": 1.144395826321104,
      "grad_norm": 0.1836690604686737,
      "learning_rate": 8.732255950360407e-06,
      "loss": 0.0186,
      "step": 850
    },
    {
      "epoch": 1.157859306630764,
      "grad_norm": 1.3435533046722412,
      "learning_rate": 8.50743967444588e-06,
      "loss": 0.0227,
      "step": 860
    },
    {
      "epoch": 1.1713227869404241,
      "grad_norm": 0.8946637511253357,
      "learning_rate": 8.28339242415468e-06,
      "loss": 0.032,
      "step": 870
    },
    {
      "epoch": 1.1847862672500842,
      "grad_norm": 1.6852998733520508,
      "learning_rate": 8.060229637418087e-06,
      "loss": 0.0232,
      "step": 880
    },
    {
      "epoch": 1.1982497475597442,
      "grad_norm": 1.1698979139328003,
      "learning_rate": 7.838066296457084e-06,
      "loss": 0.0249,
      "step": 890
    },
    {
      "epoch": 1.2117132278694043,
      "grad_norm": 1.1811504364013672,
      "learning_rate": 7.617016868538979e-06,
      "loss": 0.022,
      "step": 900
    },
    {
      "epoch": 1.2251767081790643,
      "grad_norm": 0.5352753400802612,
      "learning_rate": 7.397195246999391e-06,
      "loss": 0.0275,
      "step": 910
    },
    {
      "epoch": 1.2386401884887244,
      "grad_norm": 0.7507229447364807,
      "learning_rate": 7.178714692559937e-06,
      "loss": 0.0238,
      "step": 920
    },
    {
      "epoch": 1.2521036687983844,
      "grad_norm": 0.13147792220115662,
      "learning_rate": 6.961687774971855e-06,
      "loss": 0.0246,
      "step": 930
    },
    {
      "epoch": 1.2655671491080445,
      "grad_norm": 0.20155227184295654,
      "learning_rate": 6.746226315015667e-06,
      "loss": 0.0124,
      "step": 940
    },
    {
      "epoch": 1.2790306294177045,
      "grad_norm": 0.7085976004600525,
      "learning_rate": 6.532441326886716e-06,
      "loss": 0.0251,
      "step": 950
    },
    {
      "epoch": 1.2924941097273646,
      "grad_norm": 1.3052009344100952,
      "learning_rate": 6.320442960996306e-06,
      "loss": 0.0278,
      "step": 960
    },
    {
      "epoch": 1.3059575900370246,
      "grad_norm": 1.9183716773986816,
      "learning_rate": 6.110340447217882e-06,
      "loss": 0.035,
      "step": 970
    },
    {
      "epoch": 1.3194210703466847,
      "grad_norm": 0.8648195266723633,
      "learning_rate": 5.902242038607523e-06,
      "loss": 0.0212,
      "step": 980
    },
    {
      "epoch": 1.3328845506563447,
      "grad_norm": 0.23318058252334595,
      "learning_rate": 5.6962549556277134e-06,
      "loss": 0.0191,
      "step": 990
    },
    {
      "epoch": 1.3463480309660047,
      "grad_norm": 0.8426990509033203,
      "learning_rate": 5.492485330903159e-06,
      "loss": 0.0242,
      "step": 1000
    },
    {
      "epoch": 1.3463480309660047,
      "eval_loss": 0.0304227527230978,
      "eval_runtime": 214.7529,
      "eval_samples_per_second": 6.151,
      "eval_steps_per_second": 6.151,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1484,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.292824170225992e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
